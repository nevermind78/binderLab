{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-setup when running on Google Colab\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    !pip install --quiet openml\n",
    "    !pip install --quiet gama\n",
    "\n",
    "# General imports\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import openml as oml\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Using GAMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use AutoML tool [GAMA](https://github.com/PGijsbers/gama/).\n",
    "The exercise is self-contained, but if you want to know more the documentation is found [here](https://pgijsbers.github.io/gama/develop/).\n",
    "First, make sure GAMA is installed and/or check the right version is installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --quiet gama\n",
    "# Note: On MacOS, you may also need to install openblas, e.g. with `brew install openblas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK. You may continue :)\n"
     ]
    }
   ],
   "source": [
    "from packaging import version\n",
    "import gama\n",
    "if version.parse(gama.__version__) < version.parse(\"20.1.0\"):\n",
    "    print(\"GAMA is outdated. Please update now!\")\n",
    "else:\n",
    "    print(\"OK. You may continue :)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*note*:\n",
    "> GAMA is under active development. Parts of the interface are still subject to change. We are also using small time budgets because the lab only lasts two hours. For that reason some of the results may be affected more than usual by the randomness inherent to evolutionary search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard use case on NO<sub>2</sub> data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In lab session 1, we tested several models the predict **NO<sub>2</sub>** levels.\n",
    "Here we will use GAMA automatically find a pipeline for this task.\n",
    "First we have to fetch the data from OpenML, and split it into a train and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "no2 = oml.datasets.get_dataset(547)\n",
    "X, y, _, _ = no2.get_data(target=no2.default_target_attribute, dataset_format='dataframe');\n",
    "X = X.drop('day',axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then import and use GAMA just like a scikit-learn classifier or regressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from gama import GamaClassifier, GamaRegressor\n",
    "automl = GamaRegressor(\n",
    "    max_total_time=60, # in seconds\n",
    "    n_jobs=1,  # one subprocess\n",
    "    scoring='r2',  # metric to optimize for\n",
    "    verbosity=logging.WARNING,  # to get printed updates about search progress\n",
    "    output_directory=\"gama_log\",  # name for a log file to record search output in\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.1\n",
    "Starting AutoML is now as simple as calling `fit` with the training data. You can use the `score` function to get the model's score on the test set. Using GAMA, fit a model to the data and report the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jvanscho/miniforge3/lib/python3.9/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "/Users/jvanscho/miniforge3/lib/python3.9/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gama.GamaRegressor.GamaRegressor at 0x2a2e21940>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 1.1: Call fit and score\n",
    "automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18004587099500413"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the score compare to the maximum of `0.4796` found in lab 1?\n",
    "It's likely better. Because the dataset is so small, even in one minute time GAMA can evaluate many pipelines.\n",
    "GAMA also considers more (and different) models than those from lab 1.\n",
    "\n",
    "The number of pipelines that have been evaluated should've been printed as cell output.\n",
    "But we can also have a closer look at which pipelines have been evaluated.\n",
    "We do this by parsing the log GAMA created (filename set by `keep_analysis_log`) with the builtin `GamaReport` parser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_evaluations(df):\n",
    "    \"\"\" The GamaReport was initially developed for use within GAMA tooling.\n",
    "    For this reason it contains some hard to interpret, useless or internal data.\n",
    "    For clarity, we filter this out for you.\n",
    "    \"\"\"\n",
    "    df = df.drop(['id', 'length_cummax', 'relative_end'], axis=1)\n",
    "    df['length'] = -df['length']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing default after 0.0009s.\n",
      "\n",
      "search AsyncEA after 53.0824s.\n",
      "\n",
      "postprocess BestFitPostProcessing after 0.1582s.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>start</th>\n",
       "      <th>duration</th>\n",
       "      <th>t_process</th>\n",
       "      <th>score</th>\n",
       "      <th>pipeline</th>\n",
       "      <th>error</th>\n",
       "      <th>parent0</th>\n",
       "      <th>parent1</th>\n",
       "      <th>origin</th>\n",
       "      <th>n</th>\n",
       "      <th>r2</th>\n",
       "      <th>length</th>\n",
       "      <th>r2_cummax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19593</th>\n",
       "      <td>79783</td>\n",
       "      <td>2022-02-02 22:24:07.645673</td>\n",
       "      <td>0 days 00:00:00.000124931</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>(-inf, -2)</td>\n",
       "      <td>GradientBoostingRegressor(Nystroem(data, Nystr...</td>\n",
       "      <td>&lt;class 'TypeError'&gt; check_cv() takes from 0 to...</td>\n",
       "      <td>4aa674e3-e797-490a-b405-e125558a5f88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mut_insert</td>\n",
       "      <td>19593</td>\n",
       "      <td>-inf</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22148</th>\n",
       "      <td>79783</td>\n",
       "      <td>2022-02-02 22:24:10.818902</td>\n",
       "      <td>0 days 00:00:00.000092983</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>(-inf, -2)</td>\n",
       "      <td>GradientBoostingRegressor(MaxAbsScaler(data), ...</td>\n",
       "      <td>&lt;class 'TypeError'&gt; check_cv() takes from 0 to...</td>\n",
       "      <td>dab8c779-2661-4110-acc3-fe463080337e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mut_insert</td>\n",
       "      <td>22148</td>\n",
       "      <td>-inf</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42800</th>\n",
       "      <td>79783</td>\n",
       "      <td>2022-02-02 22:24:35.461106</td>\n",
       "      <td>0 days 00:00:00.000218153</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>(-inf, -2)</td>\n",
       "      <td>GradientBoostingRegressor(SelectFwe(data, Sele...</td>\n",
       "      <td>&lt;class 'TypeError'&gt; check_cv() takes from 0 to...</td>\n",
       "      <td>27903398-5556-469f-9c6c-e23f8593484d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mut_insert</td>\n",
       "      <td>42800</td>\n",
       "      <td>-inf</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42865</th>\n",
       "      <td>79783</td>\n",
       "      <td>2022-02-02 22:24:35.538670</td>\n",
       "      <td>0 days 00:00:00.000098944</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>(-inf, -2)</td>\n",
       "      <td>GradientBoostingRegressor(MaxAbsScaler(data), ...</td>\n",
       "      <td>&lt;class 'TypeError'&gt; check_cv() takes from 0 to...</td>\n",
       "      <td>018364fe-f35c-4c82-a383-bdccbcf7ce43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mut_insert</td>\n",
       "      <td>42865</td>\n",
       "      <td>-inf</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43600</th>\n",
       "      <td>79783</td>\n",
       "      <td>2022-02-02 22:24:36.388697</td>\n",
       "      <td>0 days 00:00:00.000099182</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>(-inf, -1)</td>\n",
       "      <td>GradientBoostingRegressor(data, GradientBoosti...</td>\n",
       "      <td>&lt;class 'TypeError'&gt; check_cv() takes from 0 to...</td>\n",
       "      <td>ec5cc934-0d3b-4fc8-95ab-2d3a17f2b338</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mut_replace_terminal</td>\n",
       "      <td>43600</td>\n",
       "      <td>-inf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pid                      start                  duration  t_process  \\\n",
       "19593  79783 2022-02-02 22:24:07.645673 0 days 00:00:00.000124931   0.000132   \n",
       "22148  79783 2022-02-02 22:24:10.818902 0 days 00:00:00.000092983   0.000101   \n",
       "42800  79783 2022-02-02 22:24:35.461106 0 days 00:00:00.000218153   0.000224   \n",
       "42865  79783 2022-02-02 22:24:35.538670 0 days 00:00:00.000098944   0.000103   \n",
       "43600  79783 2022-02-02 22:24:36.388697 0 days 00:00:00.000099182   0.000103   \n",
       "\n",
       "            score                                           pipeline  \\\n",
       "19593  (-inf, -2)  GradientBoostingRegressor(Nystroem(data, Nystr...   \n",
       "22148  (-inf, -2)  GradientBoostingRegressor(MaxAbsScaler(data), ...   \n",
       "42800  (-inf, -2)  GradientBoostingRegressor(SelectFwe(data, Sele...   \n",
       "42865  (-inf, -2)  GradientBoostingRegressor(MaxAbsScaler(data), ...   \n",
       "43600  (-inf, -1)  GradientBoostingRegressor(data, GradientBoosti...   \n",
       "\n",
       "                                                   error  \\\n",
       "19593  <class 'TypeError'> check_cv() takes from 0 to...   \n",
       "22148  <class 'TypeError'> check_cv() takes from 0 to...   \n",
       "42800  <class 'TypeError'> check_cv() takes from 0 to...   \n",
       "42865  <class 'TypeError'> check_cv() takes from 0 to...   \n",
       "43600  <class 'TypeError'> check_cv() takes from 0 to...   \n",
       "\n",
       "                                    parent0 parent1                origin  \\\n",
       "19593  4aa674e3-e797-490a-b405-e125558a5f88     NaN            mut_insert   \n",
       "22148  dab8c779-2661-4110-acc3-fe463080337e     NaN            mut_insert   \n",
       "42800  27903398-5556-469f-9c6c-e23f8593484d     NaN            mut_insert   \n",
       "42865  018364fe-f35c-4c82-a383-bdccbcf7ce43     NaN            mut_insert   \n",
       "43600  ec5cc934-0d3b-4fc8-95ab-2d3a17f2b338     NaN  mut_replace_terminal   \n",
       "\n",
       "           n   r2  length  r2_cummax  \n",
       "19593  19593 -inf     2.0       -inf  \n",
       "22148  22148 -inf     2.0       -inf  \n",
       "42800  42800 -inf     2.0       -inf  \n",
       "42865  42865 -inf     2.0       -inf  \n",
       "43600  43600 -inf     1.0       -inf  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gama.logging.GamaReport import GamaReport\n",
    "report = GamaReport(log_directory=\"gama_log\")\n",
    "evaluations = transform_evaluations(report.evaluations)\n",
    "evaluations.sample(5).sort_values(by='n')  # Show 5 random samples from the dataframe, but sort them by order of n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe has the following columns:\n",
    " - n: the n-th pipeline to be evaluated in search\n",
    " - start: start time of the evaluation\n",
    " - duration: the time it took to evaluate the model (in seconds)\n",
    " - r2: the r2 score of the pipeline (based on 5-fold cross-validation on the training data)\n",
    " - length: the number of steps in the pipeline times (i.e., length 2 means one preprocessing step and one estimator).\n",
    " - pipeline: the pipeline (more info below)\n",
    " - r2_cummax: the maximum r2 score found at evaluation `n`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.2:\n",
    "Find the best pipeline of each length from the `evaluations` dataframe (or one of the best, in case of a tie)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>start</th>\n",
       "      <th>duration</th>\n",
       "      <th>t_process</th>\n",
       "      <th>score</th>\n",
       "      <th>pipeline</th>\n",
       "      <th>error</th>\n",
       "      <th>parent0</th>\n",
       "      <th>parent1</th>\n",
       "      <th>origin</th>\n",
       "      <th>n</th>\n",
       "      <th>r2</th>\n",
       "      <th>length</th>\n",
       "      <th>r2_cummax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79783</td>\n",
       "      <td>2022-02-02 22:23:44.711950</td>\n",
       "      <td>0 days 00:00:00.000200987</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>(-inf, -3)</td>\n",
       "      <td>GradientBoostingRegressor(StandardScaler(MaxAb...</td>\n",
       "      <td>&lt;class 'TypeError'&gt; check_cv() takes from 0 to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>new</td>\n",
       "      <td>0</td>\n",
       "      <td>-inf</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29319</th>\n",
       "      <td>79783</td>\n",
       "      <td>2022-02-02 22:24:19.406984</td>\n",
       "      <td>0 days 00:00:00.000093937</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>(-inf, -1)</td>\n",
       "      <td>GradientBoostingRegressor(data, GradientBoosti...</td>\n",
       "      <td>&lt;class 'TypeError'&gt; check_cv() takes from 0 to...</td>\n",
       "      <td>b664ffba-b8e4-4989-b205-0717fbcb3995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mut_replace_terminal</td>\n",
       "      <td>29319</td>\n",
       "      <td>-inf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29311</th>\n",
       "      <td>79783</td>\n",
       "      <td>2022-02-02 22:24:19.398273</td>\n",
       "      <td>0 days 00:00:00.000107050</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>(-inf, -2)</td>\n",
       "      <td>ExtraTreesRegressor(FastICA(data, FastICA.tol=...</td>\n",
       "      <td>&lt;class 'TypeError'&gt; check_cv() takes from 0 to...</td>\n",
       "      <td>f5292317-1ea0-42a9-8ee3-505328a6bd9c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mut_insert</td>\n",
       "      <td>29311</td>\n",
       "      <td>-inf</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>79783</td>\n",
       "      <td>2022-02-02 22:23:44.748849</td>\n",
       "      <td>0 days 00:00:00.000212908</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>(-inf, -4)</td>\n",
       "      <td>DecisionTreeRegressor(StandardScaler(Normalize...</td>\n",
       "      <td>&lt;class 'TypeError'&gt; check_cv() takes from 0 to...</td>\n",
       "      <td>d4670a36-d05a-445d-9d17-18dd92f205b2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mut_insert</td>\n",
       "      <td>88</td>\n",
       "      <td>-inf</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pid                      start                  duration  t_process  \\\n",
       "0      79783 2022-02-02 22:23:44.711950 0 days 00:00:00.000200987   0.000197   \n",
       "29319  79783 2022-02-02 22:24:19.406984 0 days 00:00:00.000093937   0.000100   \n",
       "29311  79783 2022-02-02 22:24:19.398273 0 days 00:00:00.000107050   0.000112   \n",
       "88     79783 2022-02-02 22:23:44.748849 0 days 00:00:00.000212908   0.000219   \n",
       "\n",
       "            score                                           pipeline  \\\n",
       "0      (-inf, -3)  GradientBoostingRegressor(StandardScaler(MaxAb...   \n",
       "29319  (-inf, -1)  GradientBoostingRegressor(data, GradientBoosti...   \n",
       "29311  (-inf, -2)  ExtraTreesRegressor(FastICA(data, FastICA.tol=...   \n",
       "88     (-inf, -4)  DecisionTreeRegressor(StandardScaler(Normalize...   \n",
       "\n",
       "                                                   error  \\\n",
       "0      <class 'TypeError'> check_cv() takes from 0 to...   \n",
       "29319  <class 'TypeError'> check_cv() takes from 0 to...   \n",
       "29311  <class 'TypeError'> check_cv() takes from 0 to...   \n",
       "88     <class 'TypeError'> check_cv() takes from 0 to...   \n",
       "\n",
       "                                    parent0 parent1                origin  \\\n",
       "0                                       NaN     NaN                   new   \n",
       "29319  b664ffba-b8e4-4989-b205-0717fbcb3995     NaN  mut_replace_terminal   \n",
       "29311  f5292317-1ea0-42a9-8ee3-505328a6bd9c     NaN            mut_insert   \n",
       "88     d4670a36-d05a-445d-9d17-18dd92f205b2     NaN            mut_insert   \n",
       "\n",
       "           n   r2  length  r2_cummax  \n",
       "0          0 -inf     3.0       -inf  \n",
       "29319  29319 -inf     1.0       -inf  \n",
       "29311  29311 -inf     2.0       -inf  \n",
       "88        88 -inf     4.0       -inf  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 1.2: Find the best pipeline of each length\n",
    "evaluations.sort_values('r2', ascending=False).drop_duplicates(['length'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the progress of search, plot:\n",
    " - The `r2` score for each evaluation as a function of `n`, preferably only for those evaluations with an `r2` score of at least 0.\n",
    " - The maximum `r2` score as a function of `n`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='n'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluations[evaluations['r2'] > 0].plot.scatter(x='n', y='r2')\n",
    "evaluations.plot.line(x='n', y='r2_cummax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Ensembles on Covertype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will take a look at a classification problem, and change the AutoML pipeline.\n",
    "\n",
    "#### Exercise 1.3:\n",
    "Download the covertype dataset (id: 180) that we saw in lab 3.\n",
    "First take a stratified subsample of 50% of the data (using `train_test_split`).\n",
    "Then split that data into a train and test set (50%/50%). \n",
    "The train and test sets are now both 25% of the total data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a GamaClassifier, similarly to how the GamaRegressor was initialized, but:\n",
    " - specify the maximum runtime to at least 3 minutes,\n",
    " - set `n_jobs` to 2,\n",
    " - set the metric to accuracy,\n",
    " - specify a different log name,\n",
    "\n",
    "Then start search (`fit`) and evaluate the model on the test data (`score`).\n",
    "Take a short break once it's all running, or ask us a question about the lecture! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Exercise 1.3: Split the data and run GAMA\n",
    "trees = oml.datasets.get_dataset(180)\n",
    "X,y,_,_ = trees.get_data(target=trees.default_target_attribute, dataset_format='dataframe')\n",
    "X_sub, _, y_sub, _ = train_test_split(X, y, stratify=y, train_size=0.5)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sub, y_sub, stratify=y_sub, train_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAMA version 20.2.1.\n",
      "INIT:GamaClassifier(scoring=accuracy,regularize_length=True,max_pipeline_length=None,random_state=None,max_total_time=180,max_eval_time=None,n_jobs=2,max_memory_mb=None,verbosity=20,search=AsyncEA(),post_processing=BestFitPostProcessing(),output_directory=gama_log2,store=logs)\n"
     ]
    }
   ],
   "source": [
    "automl = GamaClassifier(\n",
    "    max_total_time=60,\n",
    "    n_jobs=2,\n",
    "    scoring='accuracy',\n",
    "    verbosity=logging.INFO,  # to get printed updates about search progress\n",
    "    output_directory=\"gama_log2\",  # name for a log file to record search output in\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START: preprocessing default\n",
      "STOP: preprocessing default after 0.0864s.\n",
      "START: search AsyncEA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jvanscho/miniforge3/lib/python3.9/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting EA with new population.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jvanscho/miniforge3/lib/python3.9/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "/Users/jvanscho/miniforge3/lib/python3.9/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did the model perform? In lab 3 we had about 80% accuracy after tuning the number of trees in the RandomForest. How does this model compare?\n",
    "\n",
    "The covertype dataset is quite large, and three minutes is not much time. For this reason we downsampled such that our training set contained only 25% of the original data. In our experience with these constraints, we find that GAMA can produce models with 80% accuracy, but it's also possible to see worse results. With more time we could search longer and evaluate more models on more of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.4\n",
    "\n",
    "Up to this point GAMA has been using the best found pipeline to make predictions on the test data.\n",
    "However, we saw that constructing ensembles of models can be a useful tool to gain additional performance.\n",
    "GAMA can be configured to automatically build an ensemble from the models it found during search. To do this you should initialize GAMA with the `post_processing_method` specified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gama.postprocessing import EnsemblePostProcessing\n",
    "\n",
    "automl_with_ensemble = GamaClassifier(\n",
    "    max_total_time=60,\n",
    "    n_jobs=2,\n",
    "    verbosity=logging.INFO,\n",
    "    output_directory=\"gama_log3\",\n",
    "    scoring='accuracy',\n",
    "    post_processing=EnsemblePostProcessing(),  # Specify to build an ensemble after search\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, start search and record the test set score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Exercise 1.4\n",
    "automl_with_ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = automl_with_ensemble.score(X_test, y_test)\n",
    "print(\"ensemble score: {:.4f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.5\n",
    "Note that this run was independent from the previous run. This means it might have found better or worse pipelines than last search. We cannot compare the performance of this ensemble directly to the previous best score. Run the code cell below to see how the single best pipeline would have scored *this* run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently post-hoc switching of post-processing method is not supported directly.\n",
    "# We work around this:\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "best, = automl_with_ensemble._evaluation_library.n_best(1)\n",
    "best_pipeline = best.individual.pipeline\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "test_score = best_pipeline.score(X_test, y_test)\n",
    "print(\"train score: {:.3f}, test score: {:.3f}\".format(best.score[0], test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, did it improve the performance? Was the improvement big?\n",
    "\n",
    "Normally the ensemble should perform better, though the benefit can be very marginal.\n",
    "GAMA creates an Ensemble through weighting votes of pipelines evaluated in search (for the interested, the precise procedure is described in [Caruana et al. (2004)](https://www.cs.cornell.edu/~caruana/ctp/ct.papers/caruana.icml04.icdm06long.pdf)).\n",
    "In the scenario and constraints we have set up just now, creating a good ensemble is hard.\n",
    "Can you think of some reason(s) why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Type your answer in this markdown cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution:\n",
    "> ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Recognition with AutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *note*: If you are running out of time, or are experiencing errors below, ignore the coding assigment. We are aware that in some scenarios GAMA halts on this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.6\n",
    "AutoML is still not (yet) a one-tool-fits-all solution.\n",
    "GAMA was designed to deal with tabular data.\n",
    "Last lab session you trained ConvNets to classify images in the CIFAR dataset.\n",
    "The very first model already had at least 60% accuracy, the best model had ~83% accuracy.\n",
    "We will now compare those results to GAMA:\n",
    " - download the CIFAR-10 dataset from OpenML (dataset id: 40926)\n",
    " - split the data into a train and test set (80%/20%)\n",
    " - run GAMA optimizing for accuracy, with n_jobs=1 and (at least) 5 minutes of runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results will vary wildly.\n",
    "Running it a few times can give scores ranging from ~10% accuracy to ~35% accuracy. \n",
    "More time will lead to better results, but it will not approach ConvNet levels of performance.\n",
    "Why do you think this is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Type your answer in this markdown cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution:\n",
    "> ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Other AutoML tools\n",
    "There are AutoML tools that are specifically designed to automatically learn neural network architectures. For example [AutoKeras](https://autokeras.com/) (Texas A&M University), [AutoGluon](https://autogluon.mxnet.io/) (commercial, Amazon), and [Cloud AutoML](https://cloud.google.com/automl) (commercial, Google). If you are eager, do go and compare your own ConvNet to these AutoML systems instead!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
