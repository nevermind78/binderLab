{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TL5y5fY9Jy_x"
   },
   "source": [
    "# Lab 7: Neural networks \n",
    "\n",
    "In this lab we will build dense neural networks on the MNIST dataset.\n",
    "\n",
    "Make sure you read the tutorial for this lab first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data and create train-test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google collab\n",
    "# !pip install \"numpy>=1.26\" openml --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Keras 3.9.2\n"
     ]
    }
   ],
   "source": [
    "# Global imports and settings\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openml as oml\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "print(\"Using Keras\",keras.__version__)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Rest of your original code remains the same\n",
    "mnist = oml.datasets.get_dataset(554)\n",
    "X, y, _, _ = mnist.get_data(target=mnist.default_target_attribute, dataset_format='array')\n",
    "X = X.reshape(70000, 28, 28)\n",
    "\n",
    "# Take some random examples\n",
    "from random import randint\n",
    "fig, axes = plt.subplots(1, 5,  figsize=(10, 5))\n",
    "for i in range(5):\n",
    "    n = randint(0,70000)\n",
    "    axes[i].imshow(X[n], cmap=plt.cm.gray_r)\n",
    "    axes[i].set_xticks([])\n",
    "    axes[i].set_yticks([])\n",
    "    axes[i].set_xlabel(\"{}\".format(y[n]))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JZlvdpyYKx7V"
   },
   "outputs": [],
   "source": [
    "# For MNIST, there exists a predefined stratified train-test split of 60000-10000. We therefore don't shuffle or stratify here.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=60000, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ldP-5z1B2vL"
   },
   "source": [
    "## Exercise 1: Preprocessing\n",
    "* Normalize the data: map each feature value from its current representation (an integer between 0 and 255) to a floating-point value between 0 and 1.0. \n",
    "* Store the floating-point values in `x_train_normalized` and `x_test_normalized`.\n",
    "* Map the class label to a on-hot-encoded value. Store in `y_train_encoded` and `y_test_encoded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellView": "form",
    "id": "g8HC-TDgB1D1"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "x_train_normalized = X_train / 255.0\n",
    "x_test_normalized = X_test / 255.0\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_encoded = to_categorical(y_train)\n",
    "y_test_encoded = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3014ezH3C7jT"
   },
   "source": [
    "## Exercise 2: Create a deep neural net model\n",
    "\n",
    "Implement a `create_model` function which defines the topography of the deep neural net, specifying the following:\n",
    "\n",
    "* The number of layers in the deep neural net: Use 2 dense layers for now.\n",
    "* The number of nodes in each layer: these are parameters of your function.\n",
    "* Any regularization layers. Add at least one dropout layer.\n",
    "* The optimizer and learning rate. Make the learning rate a parameter of your function as well.\n",
    "\n",
    "Consider:\n",
    "* What should be the shape of the input layer?\n",
    "* Which activation function you will need for the last layer, since this is a 10-class classification problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create and compile a 'deep' neural net\n",
    "def create_model(layer_1_units=32, layer_2_units=10, learning_rate=0.001, dropout_rate=0.3):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "id": "pedD5GhlDC-y"
   },
   "outputs": [],
   "source": [
    "def create_model(layer_1_units=32, layer_2_units=10, learning_rate=0.001, dropout_rate=0.3):\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    # Flatten 28x28 input\n",
    "    model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "    \n",
    "    # First hidden layer\n",
    "    model.add(keras.layers.Dense(units=32, activation='relu'))\n",
    "    \n",
    "    # Dropout layer\n",
    "    model.add(keras.layers.Dropout(rate=dropout_rate))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(keras.layers.Dense(units=10, activation='softmax'))\n",
    "    \n",
    "    # Compile model \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),  # Fixed parameter name\n",
    "        loss=\"categorical_crossentropy\", \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Create a training function\n",
    "Implement a `train_model` function which trains and evaluates a given model.\n",
    "It should do a train-validation split and report the train and validation loss and accuracy, and return the training history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X, y, validation_split=0.1, epochs=10, batch_size=None):\n",
    "    \"\"\"\n",
    "    model: the model to train\n",
    "    X, y: the training data and labels\n",
    "    validation_split: the percentage of data set aside for the validation set\n",
    "    epochs: the number of epochs to train for\n",
    "    batch_size: the batch size for minibatch SGD\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "def train_model(model, X, y, validation_split=0.1, epochs=10, batch_size=None):\n",
    "    \"\"\"\n",
    "    model: the model to train\n",
    "    X, y: the training data and labels\n",
    "    validation_split: the percentage of data set aside for the validation set\n",
    "    epochs: the number of epochs to train for\n",
    "    batch_size: the batch size for minibatch SGD\n",
    "    \"\"\"\n",
    "    X_train, x_val, y_train, y_val = train_test_split(X, y, test_size=validation_split, shuffle=True, stratify=y, random_state=0)\n",
    "    \n",
    "    history = model.fit(x=X_train, y=y_train, batch_size=batch_size, verbose=0,\n",
    "                        epochs=epochs, shuffle=True, validation_data=(x_val, y_val))\n",
    "    return history "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-IXYVfvM4gD"
   },
   "source": [
    "## Exercise 4: Evaluate the model\n",
    "\n",
    "Train the model with a learning rate of 0.003, 50 epochs, batch size 4000, and a validation set that is 20% of the total training data.\n",
    "Use default settings otherwise. Plot the learning curve of the loss, validation loss, accuracy, and validation accuracy. Finally, report the performance on the test set.\n",
    "\n",
    "Feel free to use the plotting function below, or implement the callback from the tutorial to see results in real time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "QF0BFRXTOeR3"
   },
   "outputs": [],
   "source": [
    "# Helper plotting function\n",
    "#\n",
    "# history: the history object returned by the fit function\n",
    "# list_of_metrics: the metrics to plot\n",
    "def plot_curve(history, list_of_metrics):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Value\")\n",
    "\n",
    "    epochs = history.epoch\n",
    "    hist = pd.DataFrame(history.history)\n",
    "\n",
    "    for m in list_of_metrics:\n",
    "        x = hist[m]\n",
    "        plt.plot(epochs[1:], x[1:], label=m, lw=2)\n",
    "\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "id": "nj3v5EKQFY8s"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "# Settings\n",
    "learning_rate = 0.003\n",
    "epochs = 50\n",
    "batch_size = 4000\n",
    "validation_split = 0.2\n",
    "\n",
    "# Create the model the model's topography.\n",
    "model = create_model(learning_rate)\n",
    "\n",
    "# Train the model on the normalized training set.\n",
    "history = train_model(model, x_train_normalized, y_train_encoded, \n",
    "                      validation_split, epochs, batch_size)\n",
    "\n",
    "# Plot a graph of the metric vs. epochs.\n",
    "list_of_metrics = ['accuracy','val_accuracy','loss','val_loss']\n",
    "plot_curve(history, list_of_metrics)\n",
    "\n",
    "# Evaluate against the test set.\n",
    "print(\"\\n Evaluation on the test set [loss, accuracy]:\")\n",
    "model.evaluate(x=x_test_normalized, y=y_test_encoded, \n",
    "               batch_size=batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5IKmk7D49_n"
   },
   "source": [
    "## Exercise 5: Optimize the model\n",
    "\n",
    "Try to optimize the model, either manually or with a tuning method. At least optimize the following:\n",
    "* the number of hidden layers \n",
    "* the number of nodes in each layer\n",
    "* the amount of dropout layers and the dropout rate\n",
    "\n",
    "Try to reach at least 96% accuracy against the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "wYG5qXpP5a9n"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "# For an example with random search, see the tutorial\n",
    "# Here, we search manually, following the following hunches:\n",
    "#   * Adding more nodes to the first hidden layer will improve accuracy. The input size is 784, so we should not make it too small\n",
    "#   * Adding a second hidden layer generally improves accuracy.\n",
    "#   * For larger models (more nodes), we need to regularize more (more dropout)\n",
    "\n",
    "batch_size = 4000 # Pretty high, but making this smaller doesn't seem to help much.\n",
    "epochs = 70\n",
    "\n",
    "# Create the model the model's topography.\n",
    "model = create_model(layer_1_units=800, layer_2_units=800, learning_rate=0.003, dropout_rate= 0.15)\n",
    "\n",
    "# Train the model on the normalized training set.\n",
    "history = train_model(model, x_train_normalized, y_train_encoded, \n",
    "                      validation_split, epochs, batch_size)\n",
    "\n",
    "# Plot a graph of the metric vs. epochs.\n",
    "list_of_metrics = ['accuracy','val_accuracy','loss','val_loss']\n",
    "plot_curve(history, list_of_metrics)\n",
    "\n",
    "# Evaluate against the test set.\n",
    "print(\"\\n Evaluation on the test set (accuracy):\")\n",
    "model.evaluate(x=x_test_normalized, y=y_test_encoded, \n",
    "               batch_size=batch_size, verbose=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 01m 35s]\n",
      "val_accuracy: 0.9683333039283752\n",
      "\n",
      "Best val_accuracy So Far: 0.981333315372467\n",
      "Total elapsed time: 00h 07m 34s\n",
      "\n",
      "Search: Running Trial #6\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "224               |192               |units1\n",
      "0.3               |0.3               |dropout1\n",
      "160               |160               |units2\n",
      "selu              |selu              |activation\n",
      "False             |True              |add_layer3\n",
      "0.0001            |0.0001            |lr\n",
      "32                |32                |units3\n",
      "\n",
      "Epoch 1/30\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7532 - loss: 0.8562 - val_accuracy: 0.9268 - val_loss: 0.2467\n",
      "Epoch 2/30\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9239 - loss: 0.2588 - val_accuracy: 0.9488 - val_loss: 0.1750\n",
      "Epoch 3/30\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9438 - loss: 0.1900 - val_accuracy: 0.9568 - val_loss: 0.1410\n",
      "Epoch 4/30\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9571 - loss: 0.1476 - val_accuracy: 0.9662 - val_loss: 0.1191\n",
      "Epoch 5/30\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9639 - loss: 0.1242 - val_accuracy: 0.9693 - val_loss: 0.1019\n",
      "Epoch 6/30\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9687 - loss: 0.1075 - val_accuracy: 0.9735 - val_loss: 0.0938\n",
      "Epoch 7/30\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9711 - loss: 0.0937 - val_accuracy: 0.9712 - val_loss: 0.0879\n",
      "Epoch 8/30\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9754 - loss: 0.0825 - val_accuracy: 0.9757 - val_loss: 0.0815\n",
      "Epoch 9/30\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9782 - loss: 0.0737 - val_accuracy: 0.9735 - val_loss: 0.0826\n",
      "Epoch 10/30\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9784 - loss: 0.0656 - val_accuracy: 0.9767 - val_loss: 0.0752\n",
      "Epoch 11/30\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9807 - loss: 0.0638 - val_accuracy: 0.9773 - val_loss: 0.0739\n",
      "Epoch 12/30\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9822 - loss: 0.0559 - val_accuracy: 0.9767 - val_loss: 0.0733\n",
      "Epoch 13/30\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9835 - loss: 0.0520 - val_accuracy: 0.9782 - val_loss: 0.0681\n",
      "Epoch 14/30\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9847 - loss: 0.0473 - val_accuracy: 0.9788 - val_loss: 0.0684\n",
      "Epoch 15/30\n",
      "\u001b[1m1074/1688\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9859 - loss: 0.0452"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(28, 28)))\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # 1ère couche dense\n",
    "    model.add(layers.Dense(\n",
    "        units=hp.Int('units1', 64, 256, step=32),\n",
    "        activation='relu'\n",
    "    ))\n",
    "    model.add(layers.Dropout(rate=hp.Float('dropout1', 0.1, 0.5, step=0.1)))\n",
    "\n",
    "    # 2e couche dense\n",
    "    model.add(layers.Dense(\n",
    "        units=hp.Int('units2', 32, 256, step=32),\n",
    "        activation=hp.Choice('activation', ['relu', 'tanh', 'selu'])\n",
    "    ))\n",
    "\n",
    "    # 3e couche dense (optionnelle)\n",
    "    if hp.Boolean('add_layer3'):\n",
    "        model.add(layers.Dense(\n",
    "            units=hp.Int('units3', 32, 128, step=32),\n",
    "            activation='relu'\n",
    "        ))\n",
    "\n",
    "    # Couche de sortie avec softmax pour classification\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    # Optimiseur avec LR\n",
    "    optimizer = keras.optimizers.Adam(\n",
    "        learning_rate=hp.Choice('lr', [1e-2, 1e-3, 1e-4])\n",
    "    )\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Séparer les données\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    x_train_normalized,\n",
    "    y_train_encoded,\n",
    "    test_size=0.1,\n",
    "    shuffle=True,\n",
    "    stratify=y_train_encoded,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# Recherche aléatoire avec 20 essais\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    max_trials=5,\n",
    "    objective='val_accuracy',\n",
    "    project_name='mnist_advanced_tuning',\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# Lancer la recherche\n",
    "tuner.search(\n",
    "    X_train, y_train,\n",
    "    epochs=30,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Récupérer le meilleur modèle\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Évaluer\n",
    "loss, accuracy = best_model.evaluate(X_val, y_val)\n",
    "print(f\"\\n✅ Meilleure accuracy sur validation : {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur nombre de neurones (1ère couche dense) : 192\n",
      "Meilleur nombre de neurones (2ème couche dense) : 96\n",
      "Meilleur taux de dropout : 0.4\n"
     ]
    }
   ],
   "source": [
    "print(f\"Meilleur nombre de neurones (1ère couche dense) : {best_model.get('units')}\")\n",
    "print(f\"Meilleur nombre de neurones (2ème couche dense) : {best_model.get('units2')}\")\n",
    "print(f\"Meilleur taux de dropout : {best_model.get('dropout')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,720</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">970</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)            │       \u001b[38;5;34m150,720\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │        \u001b[38;5;34m18,528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m970\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">170,218</span> (664.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m170,218\u001b[0m (664.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">170,218</span> (664.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m170,218\u001b[0m (664.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = tuner.hypermodel.build(best_model)\n",
    "best_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trial ID</th>\n",
       "      <th>Val Accuracy</th>\n",
       "      <th>units</th>\n",
       "      <th>units2</th>\n",
       "      <th>dropout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.218667</td>\n",
       "      <td>192</td>\n",
       "      <td>96</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.217500</td>\n",
       "      <td>96</td>\n",
       "      <td>32</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.139333</td>\n",
       "      <td>32</td>\n",
       "      <td>160</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.139333</td>\n",
       "      <td>224</td>\n",
       "      <td>32</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.184667</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Trial ID  Val Accuracy  units  units2  dropout\n",
       "0        0      0.218667    192      96      0.4\n",
       "1        1      0.217500     96      32      0.4\n",
       "2        2      0.139333     32     160      0.1\n",
       "3        3      0.139333    224      32      0.3\n",
       "4        4      0.184667    128     256      0.2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = tuner.oracle.trials\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    {\n",
    "        'Trial ID': trial.trial_id,\n",
    "        'Val Accuracy': trial.score,\n",
    "        **trial.hyperparameters.values\n",
    "    }\n",
    "    for trial in results.values()\n",
    "])\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "best_model.save(\"best_mnist_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c82add5edef483f81b080a28bbfb05e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='Image #:', max=9999), Output())…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_prediction(index)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Charger une image aléatoire depuis x_test (normalisé)\n",
    "def show_prediction(index):\n",
    "    image = x_test_normalized[index]\n",
    "    label = np.argmax(y_test_encoded[index])  # Ground truth\n",
    "\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(f\"Vraie étiquette : {label}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Prédiction\n",
    "    prediction = best_model.predict(image[np.newaxis, ...])\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    \n",
    "    print(f\"✅ Prédiction du modèle : {predicted_label}\")\n",
    "\n",
    "# Slider pour choisir une image\n",
    "index_slider = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=len(x_test_normalized)-1,\n",
    "    step=1,\n",
    "    description='Image #:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "# Affichage interactif\n",
    "widgets.interact(show_prediction, index=index_slider)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Multi-class classification with MNIST.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
