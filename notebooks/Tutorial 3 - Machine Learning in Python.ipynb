{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine Learning in Python\n",
    "Joaquin Vanschoren, Eindhoven University of Technology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why Python?\n",
    "* Many data-heavy applications are now developed in Python\n",
    "* Highly readable, less complexity, fast prototyping\n",
    "* Easy to offload number crunching to underlying C/Fortran/... \n",
    "* Easy to install and import many rich libraries\n",
    "    - numpy: efficient data structures\n",
    "    - scipy: fast numerical recipes\n",
    "    - matplotlib: high-quality graphs\n",
    "    - scikit-learn: machine learning algorithms\n",
    "    - tensorflow: neural networks\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/ML-course/master/master/notebooks/images/tut_ecosystem.jpg\" alt=\"ml\" style=\"width: 1000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Numpy, Scipy, Matplotlib\n",
    "* We'll illustrate these with a practical example\n",
    "* Many good tutorials online\n",
    "    - [Jake VanderPlas' book and notebooks](https://github.com/jakevdp/PythonDataScienceHandbook)\n",
    "    - [J.R. Johansson's notebooks](https://github.com/jrjohansson/scientific-python-lectures)\n",
    "    - [DataCamp](https://www.datacamp.com)\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import gamma\n",
    "np.random.seed(3)  # to reproduce the data\n",
    "\n",
    "def gen_web_traffic_data():\n",
    "    '''\n",
    "    This function generates some fake data that first shows a weekly pattern \n",
    "    for a couple weeks before it grows exponentially.\n",
    "    '''\n",
    "    # 31 days, 24 hours\n",
    "    x = np.arange(1, 31*24)\n",
    "    \n",
    "    # Sine wave with weekly rhythm + noise + exponential increase\n",
    "    y = np.array(200*(np.sin(2*np.pi*x/(7*24))), dtype=np.float32)\n",
    "    y += gamma.rvs(15, loc=0, scale=100, size=len(x))\n",
    "    y += 2 * np.exp(x/100.0)\n",
    "    y = np.ma.array(y, mask=[y<0])\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def plot_web_traffic(x, y, models=None, mx=None, ymax=None):\n",
    "    '''\n",
    "    Plot the web traffic (y) over time (x). \n",
    "    \n",
    "    If models is given, it is expected to be a list fitted models,\n",
    "    which will be plotted as well (used later).\n",
    "    '''\n",
    "    plt.figure(figsize=(12,6), dpi=300) # width and height of the plot in inches\n",
    "    plt.scatter(x, y, s=10)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Hits/hour\")\n",
    "    plt.xticks([w*7*24 for w in range(20)], \n",
    "               ['week %i' %w for w in range(20)])\n",
    "    \n",
    "    if models: \n",
    "        colors = ['g', 'r', 'm', 'b', 'k']\n",
    "        linestyles = ['-', '-.', '--', ':', '-']\n",
    "\n",
    "        if mx is None:\n",
    "            mx = np.linspace(0, x[-1], 1000)\n",
    "        for model, style, color in zip(models, linestyles, colors):\n",
    "            plt.plot(mx, model(mx), linestyle=style, linewidth=2, c=color)\n",
    "\n",
    "        plt.legend([\"d=%i\" % m.order for m in models], loc=\"upper left\")\n",
    "        \n",
    "    plt.autoscale()\n",
    "    if ymax:\n",
    "        plt.ylim(ymax=ymax)\n",
    "\n",
    "    plt.grid()\n",
    "    plt.ylim(ymin=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example: Modelling web traffic\n",
    "* We generate some artificial data to mimic web traffic data\n",
    "    - E.g. website visits, tweets with certain hashtag,...\n",
    "    - Weekly rhythm + noise + exponential increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "x, y = gen_web_traffic_data()\n",
    "plot_web_traffic(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Use numpy to fit some polynomial lines\n",
    "* `polyfit` fits a polynomial of degree d\n",
    "*  `poly1d` evaluates the function using the learned coefficients\n",
    "* Plot with matplotlib\n",
    "\n",
    "```python\n",
    "f2 = np.poly1d(np.polyfit(x, y, 2))\n",
    "f10 = np.poly1d(np.polyfit(x, y, 10))\n",
    "f50 = np.poly1d(np.polyfit(x, y, 50))\n",
    "\n",
    "mx = np.linspace(0, x[-1], 1000)\n",
    "plt.plot(mx, f2(mx))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f2 = np.poly1d(np.polyfit(x, y, 2))\n",
    "f10 = np.poly1d(np.polyfit(x, y, 10))\n",
    "f50 = np.poly1d(np.polyfit(x, y, 50))\n",
    "plot_web_traffic(x, y, [f2,f10,f50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Evaluate\n",
    "* Using root mean squared error: $\\sqrt{\\sum_i (f(x_i) - y_i)^2}$\n",
    "* The degree of the polynomial needs to be tuned to the data\n",
    "* Predictions don't look great. We need more sophisticated methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "mx=np.linspace(0, 6 * 7 * 24, 100)\n",
    "\n",
    "def error(f, x, y):\n",
    "    return np.sqrt(np.sum((f(x)-y)**2))\n",
    "\n",
    "@interact\n",
    "def play_with_degree(degree=(1,30,2)):\n",
    "    f = np.poly1d(np.polyfit(x, y, degree))\n",
    "    plot_web_traffic(x, y, [f], mx=mx, ymax=10000)\n",
    "    print(\"Training error for d=%i: %f\" % (f.order, error(f, x, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# scikit-learn\n",
    "One of the most prominent Python libraries for machine learning:\n",
    "\n",
    "* Contains many state-of-the-art machine learning algorithms\n",
    "* Builds on numpy (fast), implements advanced techniques\n",
    "* Wide range of evaluation measures and techniques\n",
    "* Offers [comprehensive documentation](http://scikit-learn.org/stable/documentation) about each algorithm\n",
    "* Widely used, and a wealth of [tutorials](http://scikit-learn.org/stable/user_guide.html) and code snippets are available \n",
    "* Works well with numpy, scipy, pandas, matplotlib,...\n",
    "\n",
    "**Note**: We'll repeat most of the material below in the lectures and labs on model selection and data preprocessing, but it's still very useful to study it beforehand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Algorithms\n",
    "See the [Reference](http://scikit-learn.org/dev/modules/classes.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Supervised learning:__\n",
    "\n",
    "* Linear models (Ridge, Lasso, Elastic Net, ...)\n",
    "* Support Vector Machines\n",
    "* Tree-based methods (Classification/Regression Trees, Random Forests,...)\n",
    "* Nearest neighbors\n",
    "* Neural networks \n",
    "* Gaussian Processes\n",
    "* Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Unsupervised learning:__\n",
    "    \n",
    "* Clustering (KMeans, ...)\n",
    "* Matrix Decomposition (PCA, ...)\n",
    "* Manifold Learning (Embeddings)\n",
    "* Density estimation\n",
    "* Outlier detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Model selection and evaluation:__\n",
    "\n",
    "* Cross-validation\n",
    "* Grid-search\n",
    "* Lots of metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data import\n",
    "Multiple options:\n",
    "\n",
    "* A few toy datasets are included in `sklearn.datasets`\n",
    "* Import 1000s of datasets via `sklearn.datasets.fetch_openml`\n",
    "* You can import data files (CSV) with `pandas` or `numpy`\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import load_iris, fetch_openml\n",
    "iris_data = load_iris()\n",
    "dating_data = fetch_openml(name=\"SpeedDating\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris, fetch_openml\n",
    "iris_data = load_iris()\n",
    "dating_data = fetch_openml(\"SpeedDating\", version=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These will return a `Bunch` object (similar to a `dict`)\n",
    "\n",
    "``` python\n",
    "print(\"Keys of iris_dataset: {}\".format(iris_dataset.keys()))\n",
    "print(iris_dataset['DESCR'][:193] + \"\\n...\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Keys of iris_dataset: {}\".format(iris_data.keys()))\n",
    "print(iris_data['DESCR'][:193] + \"\\n...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Targets (classes) and features are lists of strings\n",
    "* Data and target values are always numeric (ndarrays)\n",
    "\n",
    "``` python\n",
    "print(\"Targets: {}\".format(iris_data['target_names']))\n",
    "print(\"Features: {}\".format(iris_data['feature_names']))\n",
    "print(\"Shape of data: {}\".format(iris_data['data'].shape))\n",
    "print(\"First 5 rows:\\n{}\".format(iris_data['data'][:5]))\n",
    "print(\"Targets:\\n{}\".format(iris_data['target']))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Targets: {}\".format(iris_data['target_names']))\n",
    "print(\"Features: {}\".format(iris_data['feature_names']))\n",
    "print(\"Shape of data: {}\".format(iris_data['data'].shape))\n",
    "print(\"First 5 rows:\\n{}\".format(iris_data['data'][:5]))\n",
    "print(\"Targets:\\n{}\".format(iris_data['target']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building models\n",
    "All scikitlearn _estimators_ follow the same interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class SupervisedEstimator(...):\n",
    "    def __init__(self, hyperparam, ...):\n",
    "\n",
    "    def fit(self, X, y):   # Fit/model the training data\n",
    "        ...                # given data X and targets y\n",
    "        return self\n",
    "     \n",
    "    def predict(self, X):  # Make predictions\n",
    "        ...                # on unseen data X  \n",
    "        return y_pred\n",
    "    \n",
    "    def score(self, X, y): # Predict and compare to true\n",
    "        ...                # labels y                \n",
    "        return score\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training and testing data\n",
    "To evaluate our classifier, we need to test it on unseen data.  \n",
    "`train_test_split`: splits data randomly in 75% training and 25% test data.\n",
    "\n",
    "``` python\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris_data['data'], iris_data['target'], random_state=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris_data['data'], iris_data['target'], \n",
    "    random_state=0)\n",
    "print(\"X_train shape: {}\".format(X_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "print(\"X_test shape: {}\".format(X_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fitting a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model we'll build is a k-Nearest Neighbor classifier.  \n",
    "kNN is included in `sklearn.neighbors`, so let's build our first model\n",
    "\n",
    "``` python\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Making predictions\n",
    "Let's create a new example and ask the kNN model to classify it\n",
    "\n",
    "``` python\n",
    "X_new = np.array([[5, 2.9, 1, 0.2]])\n",
    "prediction = knn.predict(X_new)\n",
    "class_name = iris_data['target_names'][prediction]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "X_new = np.array([[5, 2.9, 1, 0.2]])\n",
    "prediction = knn.predict(X_new)\n",
    "print(\"Prediction: {}\".format(prediction))\n",
    "print(\"Predicted target name: {}\".format(\n",
    "       iris_data['target_names'][prediction]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluating the model\n",
    "Feeding all test examples to the model yields all predictions\n",
    "\n",
    "``` python\n",
    "y_pred = knn.predict(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "print(\"Test set predictions:\\n {}\".format(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The `score` function computes the percentage of correct predictions\n",
    "\n",
    "``` python\n",
    "knn.score(X_test, y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "print(\"Score: {:.2f}\".format(knn.score(X_test, y_test) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-validation\n",
    "\n",
    "- More stable, thorough way to estimate generalization performance\n",
    "- _k-fold cross-validation_ (CV): split (randomized) data into _k_ equal-sized parts, called _folds_\n",
    "    - First, fold 1 is the test set, and folds 2-5 comprise the training set\n",
    "    - Then, fold 2 is the test set, folds 1,3,4,5 comprise the training set\n",
    "    - Compute _k_ evaluation scores, aggregate afterwards (e.g. take the mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Cross-validation in scikit-learn\n",
    "\n",
    "* `cross_val_score` function with learner, training data, labels\n",
    "* Returns list of all scores\n",
    "    * Does 3-fold CV by default, can be changed via `cv` hyperparameter\n",
    "    * Default scoring measures are accuracy (classification) or $R^2$ (regression)\n",
    "* Even though models are built internally, they are not returned\n",
    "\n",
    "``` python\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "scores = cross_val_score(knn, iris.data, iris.target, cv=5)\n",
    "print(\"Cross-validation scores: {}\".format(scores))\n",
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))\n",
    "print(\"Variance in cross-validation score: {:.4f}\".format(np.var(scores)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "scores = cross_val_score(knn, iris.data, iris.target)\n",
    "print(\"Cross-validation scores: {}\".format(scores))\n",
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))\n",
    "print(\"Variance in cross-validation score: {:.4f}\".format(np.var(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### More variants\n",
    "* Stratified cross-validation: for inbalanced datasets\n",
    "* Leave-one-out cross-validation: for very small datasets\n",
    "* Shuffle-Split cross-validation: whenever you need to shuffle the data first\n",
    "* Repeated cross-validation: more trustworthy, but more expensive\n",
    "* Cross-validation with groups: Whenever your data contains non-independent datapoints, e.g. data points from the same patient\n",
    "* Bootstrapping: sampling with replacement, for extracting statistical properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Avoid data leakage\n",
    "- Simply taking the best performing model based on cross-validation performance yields optimistic results\n",
    "- We've already used the test data to evaluate each model!\n",
    "- Hence, we don't have an independent test set to evaluate these hyperparameter settings\n",
    "    - Information 'leaks' from test set into the final model\n",
    "- Solution: Set aside part of the training data to evaluate the hyperparameter settings\n",
    "    - Select best model on validation set\n",
    "    - Rebuild the model on the training+validation set\n",
    "    - Evaluate optimal model on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pipelines\n",
    "* Many learning algorithms are greatly affected by _how_ you represent the training data\n",
    "* Examples: Scaling, numeric/categorical values, missing values, feature selection/construction\n",
    "* We typically need chain together different algorithms\n",
    "    - Many _preprocessing_ steps\n",
    "    - Possibly many models\n",
    "* This is called a _pipeline_ (or _workflow_)\n",
    "* The best way to represent data depends not only on the semantics of the data, but also on the kind of model you are using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example: Speed dating data\n",
    "* Data collected from speed dating events\n",
    "* See https://www.openml.org/d/40536\n",
    "* Could also be collected from dating website or app\n",
    "* Real-world data:\n",
    "    - Different numeric scales\n",
    "    - Missing values\n",
    "    - Likely irrelevant features\n",
    "    - Different types: Numeric, categorical,...\n",
    "    - Input errors (e.g. 'lawyer' vs 'Lawyer')\n",
    "    \n",
    "```\n",
    "dating_data = fetch_openml(\"SpeedDating\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dating_data = fetch_openml(\"SpeedDating\", version=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Scaling\n",
    "\n",
    "When the features have different scales (their values range between very different minimum and maximum values), one feature will overpower the others. Several scaling techniques are available to solve this:  \n",
    "- `StandardScaler` rescales all features to mean=0 and variance=1\n",
    "    - Does not ensure and min/max value\n",
    "- `RobustScaler` uses the median and quartiles\n",
    "    - Median m: half of the values < m, half > m\n",
    "    - Lower Quartile lq: 1/4 of values < lq\n",
    "    - Upper Quartile uq: 1/4 of values > uq\n",
    "    - Ignores _outliers_, brings all features to same scale\n",
    "- `MinMaxScaler` brings all feature values between 0 and 1\n",
    "- `Normalizer` scales data such that the feature vector has Euclidean length 1\n",
    "    - Projects data to the unit circle\n",
    "    - Used when only the direction/angle of the data matters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Applying scaling transformations\n",
    "- Lets apply a scaling transformation _manually_, then use it to train a learning algorithm\n",
    "- First, split the data in training and test set\n",
    "- Next, we `fit` the preprocessor on the __training data__\n",
    "    - This computes the necessary transformation parameters\n",
    "    - For `MinMaxScaler`, these are the min/max values for every feature\n",
    "- After fitting, we can `transform` the training and test data \n",
    "\n",
    "```python\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Missing value imputation\n",
    "* Many sci-kit learn algorithms cannot handle missing value\n",
    "* `Imputer` replaces specific values\n",
    "    * `missing_values` (default 'NaN') placeholder for the missing value\n",
    "    * `strategy`:\n",
    "        - `mean`, replace using the mean along the axis\n",
    "        - `median`, replace using the median along the axis\n",
    "        - `most_frequent`, replace using the most frequent value\n",
    "* Many more advanced techniques exist, but not yet in scikit-learn\n",
    "    * e.g. low rank approximations (uses matrix factorization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit_transform(X1_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Feature encoding\n",
    "* scikit-learn classifiers only handle numeric data. If your features are categorical, you need to encode them first\n",
    "* `LabelEncoder` simply replaces each value with an integer value\n",
    "* `OneHotEncoder` converts a feature of $n$ values to $n$ binary features\n",
    "    * Provide `categories` as array or set to 'auto'\n",
    "    \n",
    "```python\n",
    "X_enc = OneHotEncoder(categories='auto').fit_transform(X)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* `ColumnTransformer` can apply different transformers to different features\n",
    "* Transformers can be pipelines doing multiple things\n",
    "\n",
    "```python\n",
    "numeric_features = ['age', 'pref_o_attractive']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['gender', 'd_d_age', 'field']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Building Pipelines\n",
    "* In scikit-learn, a `pipeline` combines multiple processing _steps_ in a single estimator\n",
    "* All but the last step should be transformer (have a `transform` method)\n",
    "    * The last step can be a transformer too (e.g. Scaler+PCA)\n",
    "* It has a `fit`, `predict`, and `score` method, just like any other learning algorithm\n",
    "* Pipelines are built as a list of steps, which are (name, algorithm) tuples\n",
    "    * The name can be anything you want, but can't contain `'__'`\n",
    "    * We use `'__'` to refer to the hyperparameters, e.g. `svm__C`\n",
    "* Let's build, train, and score a `MinMaxScaler` + `LinearSVC` pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "pipe = Pipeline([(\"scaler\", MinMaxScaler()), (\"svm\", LinearSVC())])\n",
    "pipe.fit(X_train, y_train).score(X_test, y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "pipe = Pipeline([(\"scaler\", MinMaxScaler()), (\"svm\", LinearSVC())])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target,\n",
    "                                                    random_state=1)\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"Test score: {:.2f}\".format(pipe.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Now with cross-validation:\n",
    "``` python\n",
    "scores = cross_val_score(pipe, cancer.data, cancer.target)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(pipe, cancer.data, cancer.target)\n",
    "print(\"Cross-validation scores: {}\".format(scores))\n",
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* We can retrieve the trained SVM by querying the right step indices\n",
    "``` python\n",
    "pipe.steps[1][1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "print(\"SVM component: {}\".format(pipe.steps[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* Or we can use the `named_steps` dictionary\n",
    "``` python\n",
    "pipe.named_steps['svm']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "print(\"SVM component: {}\".format(pipe.named_steps['svm']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* When you don't need specific names for specific steps, you can use `make_pipeline`\n",
    "    * Assigns names to steps automatically\n",
    "``` python\n",
    "pipe_short = make_pipeline(MinMaxScaler(), LinearSVC(C=100))\n",
    "print(\"Pipeline steps:\\n{}\".format(pipe_short.steps))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "# abbreviated syntax\n",
    "pipe_short = make_pipeline(MinMaxScaler(), LinearSVC(C=100))\n",
    "print(\"Pipeline steps:\\n{}\".format(pipe_short.steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model selection and Hyperparameter tuning\n",
    "* There are many algorithms to choose from\n",
    "* Most algorithms have parameters (hyperparameters) that control model complexity\n",
    "* Now that we know how to evaluate models, we can improve them selecting by `tuning` algorithms for your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can basically use any optimization technique to optimize hyperparameters:\n",
    " \n",
    "- __Grid search__\n",
    "- __Random search__\n",
    "\n",
    "More advanced techniques:\n",
    "\n",
    "- Local search\n",
    "- Racing algorithms\n",
    "- Bayesian optimization\n",
    "- Multi-armed bandits\n",
    "- Genetic algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Grid vs Random Search\n",
    "<img src=\"https://raw.githubusercontent.com/ML-course/master/master/notebooks/images/eval_gridrandom.png\" alt=\"ml\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Grid Search\n",
    "\n",
    "- For each hyperparameter, create a list of interesting/possible values\n",
    "    - E.g. For kNN: k in [1,3,5,7,9,11,33,55,77,99]\n",
    "    - E.g. For SVM: C and gamma in [$10^{-10}$..$10^{10}$]\n",
    "- Evaluate all possible combinations of hyperparameter values\n",
    "    - E.g. using cross-validation\n",
    "- Split the training data into a training and validation set\n",
    "- Select the hyperparameter values yielding the best results on the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Grid search in scikit-learn\n",
    "- Create a parameter grid as a dictionary\n",
    "    - Keys are parameter names\n",
    "    - Values are lists of hyperparameter values\n",
    "    \n",
    "``` python\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "print(\"Parameter grid:\\n{}\".format(param_grid))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "print(\"Parameter grid:\\n{}\".format(param_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- `GridSearchCV`: like a classifier that uses CV to automatically optimize its hyperparameters internally\n",
    "    - Input: (untrained) model, parameter grid, CV procedure\n",
    "    - Output: optimized model on given training data\n",
    "    - Should only have access to training data\n",
    "    \n",
    "``` python\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.svm import SVC\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        iris.data, iris.target, random_state=0)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The optimized test score and hyperparameters can easily be retrieved:\n",
    "\n",
    "``` python\n",
    "grid_search.score(X_test, y_test)\n",
    "grid_search.best_params_\n",
    "grid_search.best_score_\n",
    "grid_search.best_estimator_\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "print(\"Test set score: {:.2f}\".format(grid_search.score(X_test, y_test)))\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "print(\"Best estimator:\\n{}\".format(grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Nested cross-validation\n",
    "\n",
    "- Note that we are still using a single split to create the outer test set\n",
    "- We can also use cross-validation here\n",
    "- Nested cross-validation:\n",
    "    - Outer loop: split data in training and test sets\n",
    "    - Inner loop: run grid search, splitting the training data into train and validation sets\n",
    "- Result is a just a list of scores\n",
    "    - There will be multiple optimized models and hyperparameter settings (not returned)\n",
    "- To apply on future data, we need to train `GridSearchCV` on all data again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "``` python\n",
    "scores = cross_val_score(GridSearchCV(SVC(), param_grid, cv=5),\n",
    "                         iris.data, iris.target, cv=5)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(GridSearchCV(SVC(), param_grid, cv=5),\n",
    "                         iris.data, iris.target, cv=5)\n",
    "print(\"Cross-validation scores: \", scores)\n",
    "print(\"Mean cross-validation score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Random Search\n",
    "\n",
    "- Grid Search has a few downsides:\n",
    "    - Optimizing many hyperparameters creates a combinatorial explosion\n",
    "    - You have to predefine a grid, hence you may jump over optimal values\n",
    "- Random Search:\n",
    "    - Picks `n_iter` random parameter values\n",
    "    - Scales better, you control the number of iterations\n",
    "    - Often works better in practice, too\n",
    "        - not all hyperparameters interact strongly\n",
    "        - you don't need to explore all combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Executing random search in scikit-learn:\n",
    "    - `RandomizedSearchCV` works like `GridSearchCV`\n",
    "    - Has `n_iter` parameter for the number of iterations\n",
    "    - Search grid can use distributions instead of fixed lists\n",
    "    \n",
    "``` python\n",
    "param_grid = {'C': expon(scale=100), \n",
    "              'gamma': expon(scale=.1)}\n",
    "random_search = RandomizedSearchCV(SVC(), param_distributions=param_grid,\n",
    "                                   n_iter=20)\n",
    "random_search.fit(X_train, y_train)\n",
    "random_search.best_estimator_\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import expon\n",
    "\n",
    "param_grid = {'C': expon(scale=100), \n",
    "              'gamma': expon(scale=.1)}\n",
    "random_search = RandomizedSearchCV(SVC(), param_distributions=param_grid,\n",
    "                                   n_iter=20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        iris.data, iris.target, random_state=0)\n",
    "random_search.fit(X_train, y_train)\n",
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Using Pipelines in Grid-searches\n",
    "* We can use the pipeline as a single estimator in `cross_val_score` or `GridSearchCV`\n",
    "* To define a grid, refer to the hyperparameters of the steps\n",
    "    * Step `svm`, parameter `C` becomes `svm__C`\n",
    "    \n",
    "```python\n",
    "param_grid = {'svm__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'svm__gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "pipe = pipeline.Pipeline([(\"scaler\", MinMaxScaler()), (\"svm\", SVC(C=100))])\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'svm__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'svm__gamma': [0.001, 0.01, 0.1, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from sklearn import pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "pipe = pipeline.Pipeline([(\"scaler\", MinMaxScaler()), (\"svm\", SVC(C=100))])\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Test set score: {:.2f}\".format(grid.score(X_test, y_test)))\n",
    "print(\"Best parameters: {}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Automated Machine Learning\n",
    "* Optimizes both the pipeline and all hyperparameters\n",
    "* E.g. auto-sklearn\n",
    "    - Drop-in sklearn classifier\n",
    "    - Also optimizes pipelines (e.g. feature selection)\n",
    "    - Uses OpenML to find good models on similar datasets\n",
    "    - Lacks Windows support\n",
    "    \n",
    "```python\n",
    "automl = autosklearn.classification.AutoSklearnClassifier(\n",
    "    time_left_for_this_task=60, # sec., for entire process\n",
    "    per_run_time_limit=15, # sec., for each model\n",
    "    ml_memory_limit=1024, # MB, memory limit\n",
    ")\n",
    "automl.fit(X_train, y_train)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "latex_metadata": {
   "author": "Joaquin Vanschoren",
   "title": "Introduction"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
